#!/bin/tcsh

#SBATCH --job-name="make_eval_figure_comparison_60min"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=8G
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=01:00:00
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=make_eval_figure_comparison_60min_%A.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_standalone/ml4convection"
set TOP_U_NET_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_models/experiment13c/vanilla"
set TOP_PERSISTENCE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_models/experiment13c/persistence_model"
set TOP_OUTPUT_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_project/journal_paper/60minute_models/eval_comparison"

set BATCH_SIZES=(60)
set L2_WEIGHTS=(0.0000031623)
set LAG_TIME_STRINGS_DASHED=("0-1200-2400")

set batch_size=${BATCH_SIZES[1]}
set l2_weight=${L2_WEIGHTS[1]}
set lag_time_string_dashed=${LAG_TIME_STRINGS_DASHED[1]}

set batch_size_string=`printf "%02d" $batch_size`
set l2_weight_string=`printf "%.10f" $l2_weight`

set u_net_dir_name="${TOP_U_NET_DIR_NAME}/batch-size=${batch_size_string}_l2-weight=${l2_weight_string}_lag-times-sec=${lag_time_string_dashed}"
set u_net_eval_dir_name="${u_net_dir_name}/testing/full_grids/evaluation/matching_distance_px=4.000000"
set persistence_eval_dir_name="${TOP_PERSISTENCE_DIR_NAME}/testing/smooth4/evaluation/matching_distance_px=4.000000"
set output_dir_name="${TOP_OUTPUT_DIR_NAME}/batch-size=${batch_size_string}_l2-weight=${l2_weight_string}_lag-times-sec=${lag_time_string_dashed}"

python3 -u "${CODE_DIR_NAME}/make_eval_figure_comparison.py" \
--input_gridded_eval_dir_names "${u_net_eval_dir_name}/advanced_scores_gridded=1" "${persistence_eval_dir_name}/advanced_scores_gridded=1" \
--input_ungridded_eval_dir_names "${u_net_eval_dir_name}/advanced_scores_gridded=0" "${persistence_eval_dir_name}/advanced_scores_gridded=0" \
--model_description_strings "U-net" "Persistence_model" \
--output_dir_name="${output_dir_name}"
