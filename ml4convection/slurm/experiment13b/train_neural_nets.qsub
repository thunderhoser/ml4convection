#!/bin/tcsh

#SBATCH --job-name="train_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --nodes=1
#SBATCH --ntasks=8           # 8 tasks per node
#SBATCH --cpus-per-task=2
#SBATCH --ntasks-per-node=8  # 8 GPUs per node
#SBATCH --exclusive
#SBATCH --time=30:00:00
#SBATCH --array=1-65
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=train_neural_nets_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set BATCH_SIZE=60

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_standalone/ml4convection"
set TEMPLATE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_models/experiment13b/templates"
set TOP_OUTPUT_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_models/experiment13b"

set TRAINING_PREDICTOR_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_project/predictors/quality_controlled/partial_grids"
set VALIDN_PREDICTOR_DIR_NAME="${TRAINING_PREDICTOR_DIR_NAME}"
set TRAINING_TARGET_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml4convection_project/targets/new_echo_classification/no_tracking/omit_north_radar/partial_grids"
set VALIDN_TARGET_DIR_NAME="${TRAINING_TARGET_DIR_NAME}"

set L2_WEIGHTS=(0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000 0.0000001000 0.0000003162 0.0000010000 0.0000031623 0.0000100000)
set LAG_TIME_COUNTS=(1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 6 6 6 6 6 7 7 7 7 7 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 2 2 2 2 2 3 3 3 3 3 2 2 2 2 2)
set LAG_TIME_STRINGS_SPACED=("0" "0" "0" "0" "0" "0 600" "0 600" "0 600" "0 600" "0 600" "0 600 1200" "0 600 1200" "0 600 1200" "0 600 1200" "0 600 1200" "0 600 1200 1800" "0 600 1200 1800" "0 600 1200 1800" "0 600 1200 1800" "0 600 1200 1800" "0 600 1200 1800 2400" "0 600 1200 1800 2400" "0 600 1200 1800 2400" "0 600 1200 1800 2400" "0 600 1200 1800 2400" "0 600 1200 1800 2400 3000" "0 600 1200 1800 2400 3000" "0 600 1200 1800 2400 3000" "0 600 1200 1800 2400 3000" "0 600 1200 1800 2400 3000" "0 600 1200 1800 2400 3000 3600" "0 600 1200 1800 2400 3000 3600" "0 600 1200 1800 2400 3000 3600" "0 600 1200 1800 2400 3000 3600" "0 600 1200 1800 2400 3000 3600" "0 1200" "0 1200" "0 1200" "0 1200" "0 1200" "0 1200 2400" "0 1200 2400" "0 1200 2400" "0 1200 2400" "0 1200 2400" "0 1200 2400 3600" "0 1200 2400 3600" "0 1200 2400 3600" "0 1200 2400 3600" "0 1200 2400 3600" "0 1800" "0 1800" "0 1800" "0 1800" "0 1800" "0 1800 3600" "0 1800 3600" "0 1800 3600" "0 1800 3600" "0 1800 3600" "0 3600" "0 3600" "0 3600" "0 3600" "0 3600")
set LAG_TIME_STRINGS_DASHED=("0" "0" "0" "0" "0" "0-600" "0-600" "0-600" "0-600" "0-600" "0-600-1200" "0-600-1200" "0-600-1200" "0-600-1200" "0-600-1200" "0-600-1200-1800" "0-600-1200-1800" "0-600-1200-1800" "0-600-1200-1800" "0-600-1200-1800" "0-600-1200-1800-2400" "0-600-1200-1800-2400" "0-600-1200-1800-2400" "0-600-1200-1800-2400" "0-600-1200-1800-2400" "0-600-1200-1800-2400-3000" "0-600-1200-1800-2400-3000" "0-600-1200-1800-2400-3000" "0-600-1200-1800-2400-3000" "0-600-1200-1800-2400-3000" "0-600-1200-1800-2400-3000-3600" "0-600-1200-1800-2400-3000-3600" "0-600-1200-1800-2400-3000-3600" "0-600-1200-1800-2400-3000-3600" "0-600-1200-1800-2400-3000-3600" "0-1200" "0-1200" "0-1200" "0-1200" "0-1200" "0-1200-2400" "0-1200-2400" "0-1200-2400" "0-1200-2400" "0-1200-2400" "0-1200-2400-3600" "0-1200-2400-3600" "0-1200-2400-3600" "0-1200-2400-3600" "0-1200-2400-3600" "0-1800" "0-1800" "0-1800" "0-1800" "0-1800" "0-1800-3600" "0-1800-3600" "0-1800-3600" "0-1800-3600" "0-1800-3600" "0-3600" "0-3600" "0-3600" "0-3600" "0-3600")

set l2_weight=${L2_WEIGHTS[$SLURM_ARRAY_TASK_ID]}
set lag_time_count=${LAG_TIME_COUNTS[$SLURM_ARRAY_TASK_ID]}

set l2_weight_string=`printf "%.10f" $l2_weight`
set lag_time_count_string=`printf "%02d" $lag_time_count`

set template_file_name="${TEMPLATE_DIR_NAME}/model_l2-weight=${l2_weight_string}_num-lag-times=${lag_time_count_string}.h5"
set output_dir_name="${TOP_OUTPUT_DIR_NAME}/l2-weight=${l2_weight_string}_lag-times-sec=${LAG_TIME_STRINGS_DASHED[$SLURM_ARRAY_TASK_ID]}"
echo $output_dir_name

python3 -u "${CODE_DIR_NAME}/train_neural_net.py" \
--training_predictor_dir_name="${TRAINING_PREDICTOR_DIR_NAME}" \
--validn_predictor_dir_name="${VALIDN_PREDICTOR_DIR_NAME}" \
--training_target_dir_name="${TRAINING_TARGET_DIR_NAME}" \
--validn_target_dir_name="${VALIDN_TARGET_DIR_NAME}" \
--input_model_file_name="${template_file_name}" \
--output_model_dir_name="${output_dir_name}" \
--lead_time_seconds=1800 \
--lag_times_seconds ${LAG_TIME_STRINGS_SPACED[$SLURM_ARRAY_TASK_ID]} \
--include_time_dimension=0 \
--omit_north_radar=1 \
--normalize=1 \
--uniformize=1 \
--num_examples_per_batch=${BATCH_SIZE} \
--max_examples_per_day_in_batch=`expr $BATCH_SIZE / 8` \
--use_partial_grids=1 \
--num_epochs=1000 \
--num_training_batches_per_epoch=64 \
--num_validn_batches_per_epoch=32
